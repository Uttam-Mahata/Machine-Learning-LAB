{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265a1d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'ID': 230, 'type': 'NATIVE', 'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'venue': 'Electronic imaging', 'year': 1993, 'journal': None, 'DOI': '10.1117/12.148698', 'URL': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(breast_cancer_wisconsin_diagnostic.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53af477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the dataset to a CSV file\n",
    "import pandas as pd\n",
    "breast_cancer_wisconsin_diagnostic_df = pd.DataFrame(X)\n",
    "breast_cancer_wisconsin_diagnostic_df['target'] = y\n",
    "breast_cancer_wisconsin_diagnostic_df.to_csv('breast_cancer_wisconsin_diagnostic.csv', index=False)\n",
    "# Preprocessing required : sagaâ€™ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d61297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
      "0    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
      "1    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
      "2    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
      "3    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
      "4    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
      "\n",
      "   concavity1  concave_points1  symmetry1  fractal_dimension1  ...  texture3  \\\n",
      "0      0.3001          0.14710     0.2419             0.07871  ...     17.33   \n",
      "1      0.0869          0.07017     0.1812             0.05667  ...     23.41   \n",
      "2      0.1974          0.12790     0.2069             0.05999  ...     25.53   \n",
      "3      0.2414          0.10520     0.2597             0.09744  ...     26.50   \n",
      "4      0.1980          0.10430     0.1809             0.05883  ...     16.67   \n",
      "\n",
      "   perimeter3   area3  smoothness3  compactness3  concavity3  concave_points3  \\\n",
      "0      184.60  2019.0       0.1622        0.6656      0.7119           0.2654   \n",
      "1      158.80  1956.0       0.1238        0.1866      0.2416           0.1860   \n",
      "2      152.50  1709.0       0.1444        0.4245      0.4504           0.2430   \n",
      "3       98.87   567.7       0.2098        0.8663      0.6869           0.2575   \n",
      "4      152.20  1575.0       0.1374        0.2050      0.4000           0.1625   \n",
      "\n",
      "   symmetry3  fractal_dimension3  target  \n",
      "0     0.4601             0.11890       M  \n",
      "1     0.2750             0.08902       M  \n",
      "2     0.3613             0.08758       M  \n",
      "3     0.6638             0.17300       M  \n",
      "4     0.2364             0.07678       M  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('breast_cancer_wisconsin_diagnostic.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ab3244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   radius1             569 non-null    float64\n",
      " 1   texture1            569 non-null    float64\n",
      " 2   perimeter1          569 non-null    float64\n",
      " 3   area1               569 non-null    float64\n",
      " 4   smoothness1         569 non-null    float64\n",
      " 5   compactness1        569 non-null    float64\n",
      " 6   concavity1          569 non-null    float64\n",
      " 7   concave_points1     569 non-null    float64\n",
      " 8   symmetry1           569 non-null    float64\n",
      " 9   fractal_dimension1  569 non-null    float64\n",
      " 10  radius2             569 non-null    float64\n",
      " 11  texture2            569 non-null    float64\n",
      " 12  perimeter2          569 non-null    float64\n",
      " 13  area2               569 non-null    float64\n",
      " 14  smoothness2         569 non-null    float64\n",
      " 15  compactness2        569 non-null    float64\n",
      " 16  concavity2          569 non-null    float64\n",
      " 17  concave_points2     569 non-null    float64\n",
      " 18  symmetry2           569 non-null    float64\n",
      " 19  fractal_dimension2  569 non-null    float64\n",
      " 20  radius3             569 non-null    float64\n",
      " 21  texture3            569 non-null    float64\n",
      " 22  perimeter3          569 non-null    float64\n",
      " 23  area3               569 non-null    float64\n",
      " 24  smoothness3         569 non-null    float64\n",
      " 25  compactness3        569 non-null    float64\n",
      " 26  concavity3          569 non-null    float64\n",
      " 27  concave_points3     569 non-null    float64\n",
      " 28  symmetry3           569 non-null    float64\n",
      " 29  fractal_dimension3  569 non-null    float64\n",
      " 30  target              569 non-null    object \n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7371d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          radius1    texture1  perimeter1        area1  smoothness1  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000   569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104     0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129     0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000     0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000     0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000     0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000     0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000     0.163400   \n",
       "\n",
       "       compactness1  concavity1  concave_points1   symmetry1  \\\n",
       "count    569.000000  569.000000       569.000000  569.000000   \n",
       "mean       0.104341    0.088799         0.048919    0.181162   \n",
       "std        0.052813    0.079720         0.038803    0.027414   \n",
       "min        0.019380    0.000000         0.000000    0.106000   \n",
       "25%        0.064920    0.029560         0.020310    0.161900   \n",
       "50%        0.092630    0.061540         0.033500    0.179200   \n",
       "75%        0.130400    0.130700         0.074000    0.195700   \n",
       "max        0.345400    0.426800         0.201200    0.304000   \n",
       "\n",
       "       fractal_dimension1  ...     radius3    texture3  perimeter3  \\\n",
       "count          569.000000  ...  569.000000  569.000000  569.000000   \n",
       "mean             0.062798  ...   16.269190   25.677223  107.261213   \n",
       "std              0.007060  ...    4.833242    6.146258   33.602542   \n",
       "min              0.049960  ...    7.930000   12.020000   50.410000   \n",
       "25%              0.057700  ...   13.010000   21.080000   84.110000   \n",
       "50%              0.061540  ...   14.970000   25.410000   97.660000   \n",
       "75%              0.066120  ...   18.790000   29.720000  125.400000   \n",
       "max              0.097440  ...   36.040000   49.540000  251.200000   \n",
       "\n",
       "             area3  smoothness3  compactness3  concavity3  concave_points3  \\\n",
       "count   569.000000   569.000000    569.000000  569.000000       569.000000   \n",
       "mean    880.583128     0.132369      0.254265    0.272188         0.114606   \n",
       "std     569.356993     0.022832      0.157336    0.208624         0.065732   \n",
       "min     185.200000     0.071170      0.027290    0.000000         0.000000   \n",
       "25%     515.300000     0.116600      0.147200    0.114500         0.064930   \n",
       "50%     686.500000     0.131300      0.211900    0.226700         0.099930   \n",
       "75%    1084.000000     0.146000      0.339100    0.382900         0.161400   \n",
       "max    4254.000000     0.222600      1.058000    1.252000         0.291000   \n",
       "\n",
       "        symmetry3  fractal_dimension3  \n",
       "count  569.000000          569.000000  \n",
       "mean     0.290076            0.083946  \n",
       "std      0.061867            0.018061  \n",
       "min      0.156500            0.055040  \n",
       "25%      0.250400            0.071460  \n",
       "50%      0.282200            0.080040  \n",
       "75%      0.317900            0.092080  \n",
       "max      0.663800            0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d05db96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius1               0\n",
       "texture1              0\n",
       "perimeter1            0\n",
       "area1                 0\n",
       "smoothness1           0\n",
       "compactness1          0\n",
       "concavity1            0\n",
       "concave_points1       0\n",
       "symmetry1             0\n",
       "fractal_dimension1    0\n",
       "radius2               0\n",
       "texture2              0\n",
       "perimeter2            0\n",
       "area2                 0\n",
       "smoothness2           0\n",
       "compactness2          0\n",
       "concavity2            0\n",
       "concave_points2       0\n",
       "symmetry2             0\n",
       "fractal_dimension2    0\n",
       "radius3               0\n",
       "texture3              0\n",
       "perimeter3            0\n",
       "area3                 0\n",
       "smoothness3           0\n",
       "compactness3          0\n",
       "concavity3            0\n",
       "concave_points3       0\n",
       "symmetry3             0\n",
       "fractal_dimension3    0\n",
       "target                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6556b3",
   "metadata": {},
   "source": [
    "Implement Logistic Regression using scikit-learn package.\n",
    "- a. Use â€˜newton-cgâ€™, â€˜lbfgsâ€™, â€˜liblinearâ€™ solver for the regression model.\n",
    "- b. For each solver use â€˜l1â€™, â€˜l2â€™, â€˜noneâ€™ penalty to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acd9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 =  LogisticRegression(penalty='l2',solver='newton-cg', max_iter=1000)\n",
    "model2 =  LogisticRegression(penalty=None,solver='newton-cg', max_iter=1000)\n",
    "model3 =  LogisticRegression(penalty='l2',solver='lbfgs', max_iter=5000)\n",
    "model4 =  LogisticRegression(penalty=None,solver='lbfgs', max_iter=10000)\n",
    "model5 =  LogisticRegression(penalty='l1',solver='liblinear', max_iter=1000)\n",
    "model6 =  LogisticRegression(penalty='l2',solver='liblinear', max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac928190",
   "metadata": {},
   "source": [
    "Split the dataset in to 80:10:10 percent (train : validation : test) (use seed = 5 for\n",
    "splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebee664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb83c3",
   "metadata": {},
   "source": [
    "Train the model initially with 80% training data and create a table for the\n",
    "coefficients of all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3fe318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling completed\n",
      "Original feature range - Min: 0.000, Max: 3432.000\n",
      "Scaled feature range - Min: -3.112, Max: 12.643\n",
      "\n",
      "============================================================\n",
      "TRAINING ALL MODELS WITH 80% TRAINING DATA\n",
      "============================================================\n",
      "\n",
      "Training newton-cg + l2 model...\n",
      "Model: newton-cg + l2\n",
      "Top 5 positive coefficients:\n",
      "          Coefficient\n",
      "texture3     1.382331\n",
      "radius2      1.107252\n",
      "area2        0.987471\n",
      "radius3      0.952409\n",
      "area3        0.935504\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "compactness1          -0.305628\n",
      "fractal_dimension1    -0.350762\n",
      "texture2              -0.462874\n",
      "compactness2          -0.813274\n",
      "fractal_dimension2    -0.843716\n",
      "----------------------------------------\n",
      "\n",
      "Training newton-cg + none model...\n",
      "Model: newton-cg + none\n",
      "Top 5 positive coefficients:\n",
      "                    Coefficient\n",
      "fractal_dimension3    23.616889\n",
      "texture3              18.264028\n",
      "radius3               16.725057\n",
      "area2                 15.002828\n",
      "concavity1            14.561412\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "concave_points3       -6.967417\n",
      "texture2              -9.560919\n",
      "compactness1         -10.713635\n",
      "compactness3         -12.395269\n",
      "fractal_dimension2   -25.027506\n",
      "----------------------------------------\n",
      "\n",
      "Training lbfgs + l2 model...\n",
      "Model: lbfgs + l2\n",
      "Top 5 positive coefficients:\n",
      "          Coefficient\n",
      "texture3     1.384830\n",
      "radius2      1.106431\n",
      "area2        0.984865\n",
      "radius3      0.952037\n",
      "area3        0.932493\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "compactness1          -0.312269\n",
      "fractal_dimension1    -0.347390\n",
      "texture2              -0.467601\n",
      "compactness2          -0.811179\n",
      "fractal_dimension2    -0.838312\n",
      "----------------------------------------\n",
      "\n",
      "Training lbfgs + none model...\n",
      "Model: lbfgs + none\n",
      "Top 5 positive coefficients:\n",
      "                    Coefficient\n",
      "texture3              90.350716\n",
      "fractal_dimension3    81.507553\n",
      "area2                 65.324775\n",
      "radius2               60.386231\n",
      "concave_points1       48.861998\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "texture1             -31.645442\n",
      "compactness3         -36.292872\n",
      "texture2             -45.359211\n",
      "compactness1         -46.045283\n",
      "fractal_dimension2   -67.892078\n",
      "----------------------------------------\n",
      "\n",
      "Training liblinear + l1 model...\n",
      "Model: liblinear + l1\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "area3               4.782518\n",
      "radius2             1.821089\n",
      "texture3            1.751663\n",
      "concave_points1     1.370653\n",
      "concavity3          1.162319\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "radius3                0.000000\n",
      "fractal_dimension1    -0.000961\n",
      "fractal_dimension2    -0.310758\n",
      "texture2              -0.615336\n",
      "compactness2          -0.809081\n",
      "----------------------------------------\n",
      "\n",
      "Training liblinear + l2 model...\n",
      "Model: liblinear + l2\n",
      "Top 5 positive coefficients:\n",
      "          Coefficient\n",
      "texture3     1.365356\n",
      "radius2      1.114510\n",
      "area2        1.050100\n",
      "area3        1.008746\n",
      "radius3      0.960305\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "fractal_dimension1    -0.300252\n",
      "compactness1          -0.328479\n",
      "texture2              -0.456315\n",
      "fractal_dimension2    -0.791780\n",
      "compactness2          -0.831553\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing - scaling the features as recommended in scikit-learn documentation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for better convergence (especially important for saga solver)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling completed\")\n",
    "print(f\"Original feature range - Min: {X_train.values.min():.3f}, Max: {X_train.values.max():.3f}\")\n",
    "print(f\"Scaled feature range - Min: {X_train_scaled.min():.3f}, Max: {X_train_scaled.max():.3f}\")\n",
    "\n",
    "# Train all models initially with 80% training data (using scaled data)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING ALL MODELS WITH 80% TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# All valid solver-penalty combinations based on scikit-learn documentation\n",
    "model_configs = [\n",
    "    {'name': 'newton-cg + l2', 'penalty': 'l2', 'solver': 'newton-cg', 'max_iter': 1000},\n",
    "    {'name': 'newton-cg + none', 'penalty': None, 'solver': 'newton-cg', 'max_iter': 1000},\n",
    "    {'name': 'lbfgs + l2', 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 5000},\n",
    "    {'name': 'lbfgs + none', 'penalty': None, 'solver': 'lbfgs', 'max_iter': 10000},\n",
    "    {'name': 'liblinear + l1', 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 1000},\n",
    "    {'name': 'liblinear + l2', 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000},\n",
    "]\n",
    "\n",
    "# Dictionary to store trained models\n",
    "models = {}\n",
    "\n",
    "for config in model_configs:\n",
    "    print(f\"\\nTraining {config['name']} model...\")\n",
    "    model = LogisticRegression(\n",
    "        penalty=config['penalty'], \n",
    "        solver=config['solver'], \n",
    "        max_iter=config['max_iter'],\n",
    "        random_state=5\n",
    "    )\n",
    "    \n",
    "    # Train on scaled training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Store the model\n",
    "    models[config['name']] = model\n",
    "    \n",
    "    # Display coefficients\n",
    "    coefficients = pd.DataFrame(model.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "    coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "    \n",
    "    print(f\"Model: {config['name']}\")\n",
    "    print(f\"Top 5 positive coefficients:\")\n",
    "    print(coefficients.head())\n",
    "    print(f\"Top 5 negative coefficients:\")\n",
    "    print(coefficients.tail())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04d81190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL MODEL PERFORMANCE SUMMARY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Summary and Conclusions\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create summary DataFrame for all models tested\n",
    "all_models_summary = []\n",
    "\n",
    "# Add original models\n",
    "for i, (solver, penalty) in enumerate([(('newton-cg', 'l2')), (('lbfgs', 'l2')), \n",
    "                                       (('liblinear', 'l1')), (('liblinear', 'l2')), \n",
    "                                       (('lbfgs', 'none')), (('newton-cg', 'none'))]):\n",
    "    model_name = f\"Model {i+1} ({solver}, {penalty})\"\n",
    "    # These were evaluated in the previous cell\n",
    "    all_models_summary.append({\n",
    "        'Model': model_name,\n",
    "        'Solver': solver,\n",
    "        'Penalty': penalty,\n",
    "        'Type': 'Original'\n",
    "    })\n",
    "\n",
    "# Add best L1 penalty models (if any were found)\n",
    "if 'best_l1_models' in locals():\n",
    "    for solver, best_info in best_l1_models.items():\n",
    "        if best_info['penalty'] is not None:\n",
    "            model_name = f\"Best L1 {solver.title()}\"\n",
    "            all_models_summary.append({\n",
    "                'Model': model_name,\n",
    "                'Solver': solver,\n",
    "                'Penalty': f\"l1 (C={best_info['penalty']})\",\n",
    "                'Type': 'Optimized L1'\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c8cec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINE-TUNING ALL MODELS WITH VALIDATION DATA\n",
      "============================================================\n",
      "\n",
      "Fine-tuning newton-cg + l2 model...\n",
      "Fine-tuned Model: newton-cg + l2\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "radius2             0.922236\n",
      "perimeter2          0.634855\n",
      "area2               0.569182\n",
      "concave_points3     0.544073\n",
      "texture2            0.516709\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "symmetry1             -0.215974\n",
      "concavity2            -0.222184\n",
      "fractal_dimension2    -0.240039\n",
      "compactness2          -0.453032\n",
      "smoothness2           -0.616058\n",
      "----------------------------------------\n",
      "\n",
      "Fine-tuning newton-cg + none model...\n",
      "Fine-tuned Model: newton-cg + none\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "radius2             5.337712\n",
      "perimeter2          3.481433\n",
      "area2               3.230989\n",
      "texture2            2.972137\n",
      "concave_points3     2.806386\n",
      "Top 5 negative coefficients:\n",
      "              Coefficient\n",
      "concavity2      -1.299230\n",
      "compactness1    -1.996560\n",
      "symmetry1       -2.143378\n",
      "compactness2    -2.803993\n",
      "smoothness2     -3.484534\n",
      "----------------------------------------\n",
      "\n",
      "Fine-tuning lbfgs + l2 model...\n",
      "Fine-tuned Model: lbfgs + l2\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "radius2             0.922776\n",
      "perimeter2          0.635401\n",
      "area2               0.568421\n",
      "concave_points3     0.543497\n",
      "texture2            0.517922\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "symmetry1             -0.215673\n",
      "concavity2            -0.221926\n",
      "fractal_dimension2    -0.241621\n",
      "compactness2          -0.453536\n",
      "smoothness2           -0.616900\n",
      "----------------------------------------\n",
      "\n",
      "Fine-tuning lbfgs + none model...\n",
      "Fine-tuned Model: lbfgs + none\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "radius2             5.145189\n",
      "perimeter2          3.532814\n",
      "area2               2.895905\n",
      "concave_points3     2.889347\n",
      "texture2            2.512464\n",
      "Top 5 negative coefficients:\n",
      "              Coefficient\n",
      "compactness1    -1.452883\n",
      "symmetry1       -2.039171\n",
      "compactness2    -2.850870\n",
      "smoothness2     -3.990160\n",
      "concavity2      -4.694903\n",
      "----------------------------------------\n",
      "\n",
      "Fine-tuning liblinear + l1 model...\n",
      "Fine-tuned Model: liblinear + l1\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "radius2             1.860572\n",
      "concave_points3     1.373493\n",
      "radius3             1.110897\n",
      "area3               0.915258\n",
      "texture3            0.874390\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "perimeter3             0.000000\n",
      "symmetry3              0.000000\n",
      "fractal_dimension3     0.000000\n",
      "concavity2            -0.015225\n",
      "smoothness2           -0.166814\n",
      "----------------------------------------\n",
      "\n",
      "Fine-tuning liblinear + l2 model...\n",
      "Fine-tuned Model: liblinear + l2\n",
      "Top 5 positive coefficients:\n",
      "                 Coefficient\n",
      "radius2             0.926811\n",
      "perimeter2          0.635742\n",
      "area2               0.603555\n",
      "concave_points3     0.553850\n",
      "area3               0.490639\n",
      "Top 5 negative coefficients:\n",
      "                    Coefficient\n",
      "compactness1          -0.219153\n",
      "symmetry1             -0.238524\n",
      "fractal_dimension1    -0.246612\n",
      "compactness2          -0.453448\n",
      "smoothness2           -0.571186\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune all models with the remaining validation partition of the dataset (10% of original dataset)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINE-TUNING ALL MODELS WITH VALIDATION DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dictionary to store fine-tuned models\n",
    "fine_tuned_models = {}\n",
    "\n",
    "for config in model_configs:\n",
    "    print(f\"\\nFine-tuning {config['name']} model...\")\n",
    "    \n",
    "    # Create a new model instance for fine-tuning\n",
    "    fine_tuned_model = LogisticRegression(\n",
    "        penalty=config['penalty'], \n",
    "        solver=config['solver'], \n",
    "        max_iter=config['max_iter'],\n",
    "        random_state=5\n",
    "    )\n",
    "    \n",
    "    # Fine-tune on scaled validation data\n",
    "    fine_tuned_model.fit(X_val_scaled, y_val)\n",
    "    \n",
    "    # Store the fine-tuned model\n",
    "    fine_tuned_models[config['name']] = fine_tuned_model\n",
    "    \n",
    "    # Display updated coefficients\n",
    "    coefficients = pd.DataFrame(fine_tuned_model.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "    coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "    \n",
    "    print(f\"Fine-tuned Model: {config['name']}\")\n",
    "    print(f\"Top 5 positive coefficients:\")\n",
    "    print(coefficients.head())\n",
    "    print(f\"Top 5 negative coefficients:\")\n",
    "    print(coefficients.tail())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9c821c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VARYING L1 PENALTY OVER THE RANGE (0.1, 0.25, 0.75, 0.9) FOR EACH SOLVER\n",
      "================================================================================\n",
      "\n",
      "LIBLINEAR SOLVER - L1 PENALTY VARIATION:\n",
      "--------------------------------------------------\n",
      "\n",
      "Training liblinear with L1 penalty (C=0.1)...\n",
      "Solver: liblinear, C=0.1 (L1 penalty)\n",
      "Non-zero coefficients: 10/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "radius3             1.202234\n",
      "concave_points1     0.883448\n",
      "area3               0.786302\n",
      "texture3            0.639356\n",
      "concave_points3     0.536189\n",
      "------------------------------\n",
      "\n",
      "Training liblinear with L1 penalty (C=0.25)...\n",
      "Solver: liblinear, C=0.25 (L1 penalty)\n",
      "Non-zero coefficients: 11/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "area3               2.845072\n",
      "concave_points1     0.913813\n",
      "radius2             0.803578\n",
      "texture3            0.791908\n",
      "radius3             0.613388\n",
      "------------------------------\n",
      "\n",
      "Training liblinear with L1 penalty (C=0.75)...\n",
      "Solver: liblinear, C=0.75 (L1 penalty)\n",
      "Non-zero coefficients: 15/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "area3               4.636379\n",
      "radius2             1.647375\n",
      "texture3            1.341270\n",
      "concave_points1     1.313176\n",
      "concavity3          1.010722\n",
      "------------------------------\n",
      "\n",
      "Training liblinear with L1 penalty (C=0.9)...\n",
      "Solver: liblinear, C=0.9 (L1 penalty)\n",
      "Non-zero coefficients: 16/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "area3               3.697674\n",
      "texture3            1.602576\n",
      "area2               1.499765\n",
      "radius2             1.429604\n",
      "concave_points1     1.247002\n",
      "------------------------------\n",
      "\n",
      "SAGA SOLVER - L1 PENALTY VARIATION:\n",
      "--------------------------------------------------\n",
      "\n",
      "Training saga with L1 penalty (C=0.1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: saga, C=0.1 (L1 penalty)\n",
      "Non-zero coefficients: 9/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "radius3             1.854050\n",
      "concave_points3     0.936932\n",
      "texture3            0.683491\n",
      "concave_points1     0.678246\n",
      "perimeter3          0.134337\n",
      "------------------------------\n",
      "\n",
      "Training saga with L1 penalty (C=0.25)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: saga, C=0.25 (L1 penalty)\n",
      "Non-zero coefficients: 12/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "radius3             2.343841\n",
      "texture3            0.890924\n",
      "radius2             0.751285\n",
      "concave_points1     0.747215\n",
      "concave_points3     0.713671\n",
      "------------------------------\n",
      "\n",
      "Training saga with L1 penalty (C=0.75)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: saga, C=0.75 (L1 penalty)\n",
      "Non-zero coefficients: 18/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "radius3             1.900050\n",
      "radius2             1.710278\n",
      "texture3            1.448598\n",
      "area3               1.368407\n",
      "concave_points1     1.014892\n",
      "------------------------------\n",
      "\n",
      "Training saga with L1 penalty (C=0.9)...\n",
      "Solver: saga, C=0.9 (L1 penalty)\n",
      "Non-zero coefficients: 20/30\n",
      "Top 5 largest absolute coefficients:\n",
      "                 Coefficient\n",
      "radius3             1.849515\n",
      "radius2             1.794175\n",
      "texture3            1.711076\n",
      "area3               1.446337\n",
      "concave_points1     1.019573\n",
      "------------------------------\n",
      "\n",
      "============================================================\n",
      "SPARSITY COMPARISON ACROSS DIFFERENT C VALUES\n",
      "============================================================\n",
      "      Solver  C_value  Non_zero_coefficients  Sparsity_ratio\n",
      "0  liblinear     0.10                     10        0.333333\n",
      "1  liblinear     0.25                     11        0.366667\n",
      "2  liblinear     0.75                     15        0.500000\n",
      "3  liblinear     0.90                     16        0.533333\n",
      "4       saga     0.10                      9        0.300000\n",
      "5       saga     0.25                     12        0.400000\n",
      "6       saga     0.75                     18        0.600000\n",
      "7       saga     0.90                     20        0.666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uttam/Machine-Learning-LAB/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Part iii: For every solver vary the 'l1' penalty over the range (0.1, 0.25, 0.75, 0.9) \n",
    "# and compare the coefficients of the features.\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARYING L1 PENALTY OVER THE RANGE (0.1, 0.25, 0.75, 0.9) FOR EACH SOLVER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Note: Only liblinear and saga solvers support L1 penalty\n",
    "# Adding saga solver for L1 penalty analysis\n",
    "l1_penalty_values = [0.1, 0.25, 0.75, 0.9]\n",
    "l1_compatible_solvers = ['liblinear', 'saga']\n",
    "\n",
    "# Dictionary to store models with different L1 penalties\n",
    "l1_penalty_models = {}\n",
    "\n",
    "for solver in l1_compatible_solvers:\n",
    "    print(f\"\\n{solver.upper()} SOLVER - L1 PENALTY VARIATION:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    l1_penalty_models[solver] = {}\n",
    "    \n",
    "    for C_value in l1_penalty_values:\n",
    "        print(f\"\\nTraining {solver} with L1 penalty (C={C_value})...\")\n",
    "        \n",
    "        # Create model with L1 penalty (C is the inverse of regularization strength)\n",
    "        model = LogisticRegression(\n",
    "            penalty='l1', \n",
    "            solver=solver, \n",
    "            C=C_value,  # Inverse of regularization strength\n",
    "            max_iter=2000,\n",
    "            random_state=5\n",
    "        )\n",
    "        \n",
    "        # Train on scaled training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Store the model\n",
    "        l1_penalty_models[solver][C_value] = model\n",
    "        \n",
    "        # Display coefficients\n",
    "        coefficients = pd.DataFrame(model.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "        coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "        \n",
    "        # Count non-zero coefficients (sparsity)\n",
    "        non_zero_coef = (coefficients['Coefficient'] != 0).sum()\n",
    "        \n",
    "        print(f\"Solver: {solver}, C={C_value} (L1 penalty)\")\n",
    "        print(f\"Non-zero coefficients: {non_zero_coef}/{len(coefficients)}\")\n",
    "        print(\"Top 5 largest absolute coefficients:\")\n",
    "        abs_coefficients = coefficients.copy()\n",
    "        abs_coefficients['Abs_Coefficient'] = abs_coefficients['Coefficient'].abs()\n",
    "        abs_coefficients = abs_coefficients.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "        print(abs_coefficients[['Coefficient']].head())\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Compare sparsity across different C values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPARSITY COMPARISON ACROSS DIFFERENT C VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sparsity_data = []\n",
    "for solver in l1_compatible_solvers:\n",
    "    for C_value in l1_penalty_values:\n",
    "        model = l1_penalty_models[solver][C_value]\n",
    "        non_zero_coef = (model.coef_.flatten() != 0).sum()\n",
    "        sparsity_data.append({\n",
    "            'Solver': solver,\n",
    "            'C_value': C_value,\n",
    "            'Non_zero_coefficients': non_zero_coef,\n",
    "            'Sparsity_ratio': non_zero_coef / len(X.columns)\n",
    "        })\n",
    "\n",
    "sparsity_df = pd.DataFrame(sparsity_data)\n",
    "print(sparsity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2664c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION ON TEST SET (10% OF DATA)\n",
      "================================================================================\n",
      "\n",
      "PART A: EVALUATION BEFORE FINE-TUNING\n",
      "--------------------------------------------------\n",
      "\n",
      "newton-cg + l2 (Before Fine-tuning):\n",
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9756\n",
      "\n",
      "newton-cg + none (Before Fine-tuning):\n",
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9756\n",
      "\n",
      "lbfgs + l2 (Before Fine-tuning):\n",
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9756\n",
      "\n",
      "lbfgs + none (Before Fine-tuning):\n",
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9756\n",
      "\n",
      "liblinear + l1 (Before Fine-tuning):\n",
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9756\n",
      "\n",
      "liblinear + l2 (Before Fine-tuning):\n",
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9756\n",
      "\n",
      "SUMMARY TABLE - BEFORE FINE-TUNING:\n",
      "                                   Model  Accuracy  Precision  Recall  \\\n",
      "0    newton-cg + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "1  newton-cg + none (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "2        lbfgs + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "3      lbfgs + none (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "4    liblinear + l1 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "5    liblinear + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "\n",
      "   F1_Score  \n",
      "0    0.9756  \n",
      "1    0.9756  \n",
      "2    0.9756  \n",
      "3    0.9756  \n",
      "4    0.9756  \n",
      "5    0.9756  \n",
      "\n",
      "============================================================\n",
      "PART B: EVALUATION AFTER FINE-TUNING\n",
      "--------------------------------------------------\n",
      "\n",
      "newton-cg + l2 (After Fine-tuning):\n",
      "Accuracy: 0.9649\n",
      "Precision: 0.9524\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9524\n",
      "\n",
      "newton-cg + none (After Fine-tuning):\n",
      "Accuracy: 0.9474\n",
      "Precision: 0.9500\n",
      "Recall: 0.9048\n",
      "F1-Score: 0.9268\n",
      "\n",
      "lbfgs + l2 (After Fine-tuning):\n",
      "Accuracy: 0.9649\n",
      "Precision: 0.9524\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9524\n",
      "\n",
      "lbfgs + none (After Fine-tuning):\n",
      "Accuracy: 0.9298\n",
      "Precision: 0.9474\n",
      "Recall: 0.8571\n",
      "F1-Score: 0.9000\n",
      "\n",
      "liblinear + l1 (After Fine-tuning):\n",
      "Accuracy: 0.9649\n",
      "Precision: 0.9524\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9524\n",
      "\n",
      "liblinear + l2 (After Fine-tuning):\n",
      "Accuracy: 0.9649\n",
      "Precision: 0.9524\n",
      "Recall: 0.9524\n",
      "F1-Score: 0.9524\n",
      "\n",
      "SUMMARY TABLE - AFTER FINE-TUNING:\n",
      "                                  Model  Accuracy  Precision  Recall  F1_Score\n",
      "0    newton-cg + l2 (after fine-tuning)    0.9649     0.9524  0.9524    0.9524\n",
      "1  newton-cg + none (after fine-tuning)    0.9474     0.9500  0.9048    0.9268\n",
      "2        lbfgs + l2 (after fine-tuning)    0.9649     0.9524  0.9524    0.9524\n",
      "3      lbfgs + none (after fine-tuning)    0.9298     0.9474  0.8571    0.9000\n",
      "4    liblinear + l1 (after fine-tuning)    0.9649     0.9524  0.9524    0.9524\n",
      "5    liblinear + l2 (after fine-tuning)    0.9649     0.9524  0.9524    0.9524\n"
     ]
    }
   ],
   "source": [
    "# Part iv: Using the test split (10%) to show accuracy, precision, recall, F1-score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION ON TEST SET (10% OF DATA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate a model and return metrics\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='M')  # M for Malignant\n",
    "    recall = recall_score(y_test, y_pred, pos_label='M')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='M')\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1_Score': f1\n",
    "    }\n",
    "\n",
    "# Part iv.a: Show output for every possible combination of solver-penalty BEFORE fine-tuning\n",
    "print(\"\\nPART A: EVALUATION BEFORE FINE-TUNING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "before_fine_tuning_results = []\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config['name']\n",
    "    model = models[model_name]\n",
    "    \n",
    "    result = evaluate_model(model, X_test_scaled, y_test, f\"{model_name} (before fine-tuning)\")\n",
    "    before_fine_tuning_results.append(result)\n",
    "    \n",
    "    print(f\"\\n{model_name} (Before Fine-tuning):\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['Precision']:.4f}\")\n",
    "    print(f\"Recall: {result['Recall']:.4f}\")\n",
    "    print(f\"F1-Score: {result['F1_Score']:.4f}\")\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "before_df = pd.DataFrame(before_fine_tuning_results)\n",
    "print(\"\\nSUMMARY TABLE - BEFORE FINE-TUNING:\")\n",
    "print(before_df.round(4))\n",
    "\n",
    "# Part iv.b: Show output for every possible combination of solver-penalty AFTER fine-tuning\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PART B: EVALUATION AFTER FINE-TUNING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "after_fine_tuning_results = []\n",
    "\n",
    "for config in model_configs:\n",
    "    model_name = config['name']\n",
    "    model = fine_tuned_models[model_name]\n",
    "    \n",
    "    result = evaluate_model(model, X_test_scaled, y_test, f\"{model_name} (after fine-tuning)\")\n",
    "    after_fine_tuning_results.append(result)\n",
    "    \n",
    "    print(f\"\\n{model_name} (After Fine-tuning):\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {result['Precision']:.4f}\")\n",
    "    print(f\"Recall: {result['Recall']:.4f}\")\n",
    "    print(f\"F1-Score: {result['F1_Score']:.4f}\")\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "after_df = pd.DataFrame(after_fine_tuning_results)\n",
    "print(\"\\nSUMMARY TABLE - AFTER FINE-TUNING:\")\n",
    "print(after_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1bcc1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART C: COMPARISON AND IMPROVEMENT ANALYSIS\n",
      "================================================================================\n",
      "COMPREHENSIVE COMPARISON TABLE:\n",
      "              Model  Accuracy_Before  Accuracy_After  Accuracy_Improvement  \\\n",
      "0    newton-cg + l2           0.9825          0.9649               -0.0175   \n",
      "1  newton-cg + none           0.9825          0.9474               -0.0351   \n",
      "2        lbfgs + l2           0.9825          0.9649               -0.0175   \n",
      "3      lbfgs + none           0.9825          0.9298               -0.0526   \n",
      "4    liblinear + l1           0.9825          0.9649               -0.0175   \n",
      "5    liblinear + l2           0.9825          0.9649               -0.0175   \n",
      "\n",
      "   F1_Before  F1_After  F1_Improvement  Precision_Before  Precision_After  \\\n",
      "0     0.9756    0.9524         -0.0232               1.0           0.9524   \n",
      "1     0.9756    0.9268         -0.0488               1.0           0.9500   \n",
      "2     0.9756    0.9524         -0.0232               1.0           0.9524   \n",
      "3     0.9756    0.9000         -0.0756               1.0           0.9474   \n",
      "4     0.9756    0.9524         -0.0232               1.0           0.9524   \n",
      "5     0.9756    0.9524         -0.0232               1.0           0.9524   \n",
      "\n",
      "   Recall_Before  Recall_After  \n",
      "0         0.9524        0.9524  \n",
      "1         0.9524        0.9048  \n",
      "2         0.9524        0.9524  \n",
      "3         0.9524        0.8571  \n",
      "4         0.9524        0.9524  \n",
      "5         0.9524        0.9524  \n",
      "\n",
      "BEST MODELS ANALYSIS:\n",
      "------------------------------\n",
      "Best model before fine-tuning: newton-cg + l2 (before fine-tuning)\n",
      "  - Accuracy: 0.9825\n",
      "  - F1-Score: 0.9756\n",
      "\n",
      "Best model after fine-tuning: newton-cg + l2 (after fine-tuning)\n",
      "  - Accuracy: 0.9649\n",
      "  - F1-Score: 0.9524\n",
      "\n",
      "AVERAGE IMPROVEMENTS:\n",
      "  - Average Accuracy Improvement: -0.0263\n",
      "  - Average F1-Score Improvement: -0.0362\n",
      "\n",
      "============================================================\n",
      "L1 PENALTY MODELS EVALUATION\n",
      "============================================================\n",
      "\n",
      "LIBLINEAR SOLVER - L1 PENALTY EVALUATION:\n",
      "----------------------------------------\n",
      "C=0.1: Accuracy=0.9825, F1=0.9756\n",
      "C=0.25: Accuracy=0.9825, F1=0.9756\n",
      "C=0.75: Accuracy=0.9825, F1=0.9756\n",
      "C=0.9: Accuracy=0.9825, F1=0.9756\n",
      "\n",
      "SAGA SOLVER - L1 PENALTY EVALUATION:\n",
      "----------------------------------------\n",
      "C=0.1: Accuracy=0.9825, F1=0.9756\n",
      "C=0.25: Accuracy=0.9825, F1=0.9756\n",
      "C=0.75: Accuracy=0.9825, F1=0.9756\n",
      "C=0.9: Accuracy=0.9825, F1=0.9756\n",
      "\n",
      "L1 PENALTY MODELS SUMMARY:\n",
      "                Model  Accuracy  Precision  Recall  F1_Score\n",
      "0   liblinear_L1_C0.1    0.9825        1.0  0.9524    0.9756\n",
      "1  liblinear_L1_C0.25    0.9825        1.0  0.9524    0.9756\n",
      "2  liblinear_L1_C0.75    0.9825        1.0  0.9524    0.9756\n",
      "3   liblinear_L1_C0.9    0.9825        1.0  0.9524    0.9756\n",
      "4        saga_L1_C0.1    0.9825        1.0  0.9524    0.9756\n",
      "5       saga_L1_C0.25    0.9825        1.0  0.9524    0.9756\n",
      "6       saga_L1_C0.75    0.9825        1.0  0.9524    0.9756\n",
      "7        saga_L1_C0.9    0.9825        1.0  0.9524    0.9756\n"
     ]
    }
   ],
   "source": [
    "# Part iv.c: Comment on the improvement, if any\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART C: COMPARISON AND IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_results = []\n",
    "\n",
    "for i, config in enumerate(model_configs):\n",
    "    model_name = config['name']\n",
    "    \n",
    "    before_metrics = before_fine_tuning_results[i]\n",
    "    after_metrics = after_fine_tuning_results[i]\n",
    "    \n",
    "    comparison = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy_Before': before_metrics['Accuracy'],\n",
    "        'Accuracy_After': after_metrics['Accuracy'],\n",
    "        'Accuracy_Improvement': after_metrics['Accuracy'] - before_metrics['Accuracy'],\n",
    "        'F1_Before': before_metrics['F1_Score'],\n",
    "        'F1_After': after_metrics['F1_Score'],\n",
    "        'F1_Improvement': after_metrics['F1_Score'] - before_metrics['F1_Score'],\n",
    "        'Precision_Before': before_metrics['Precision'],\n",
    "        'Precision_After': after_metrics['Precision'],\n",
    "        'Recall_Before': before_metrics['Recall'],\n",
    "        'Recall_After': after_metrics['Recall'],\n",
    "    }\n",
    "    comparison_results.append(comparison)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(\"COMPREHENSIVE COMPARISON TABLE:\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Find best models\n",
    "print(f\"\\nBEST MODELS ANALYSIS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Before fine-tuning\n",
    "best_before = before_df.loc[before_df['Accuracy'].idxmax()]\n",
    "print(f\"Best model before fine-tuning: {best_before['Model']}\")\n",
    "print(f\"  - Accuracy: {best_before['Accuracy']:.4f}\")\n",
    "print(f\"  - F1-Score: {best_before['F1_Score']:.4f}\")\n",
    "\n",
    "# After fine-tuning  \n",
    "best_after = after_df.loc[after_df['Accuracy'].idxmax()]\n",
    "print(f\"\\nBest model after fine-tuning: {best_after['Model']}\")\n",
    "print(f\"  - Accuracy: {best_after['Accuracy']:.4f}\")\n",
    "print(f\"  - F1-Score: {best_after['F1_Score']:.4f}\")\n",
    "\n",
    "# Average improvements\n",
    "avg_accuracy_improvement = comparison_df['Accuracy_Improvement'].mean()\n",
    "avg_f1_improvement = comparison_df['F1_Improvement'].mean()\n",
    "\n",
    "print(f\"\\nAVERAGE IMPROVEMENTS:\")\n",
    "print(f\"  - Average Accuracy Improvement: {avg_accuracy_improvement:.4f}\")\n",
    "print(f\"  - Average F1-Score Improvement: {avg_f1_improvement:.4f}\")\n",
    "\n",
    "# Analyze L1 penalty models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"L1 PENALTY MODELS EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "l1_evaluation_results = []\n",
    "\n",
    "for solver in l1_compatible_solvers:\n",
    "    print(f\"\\n{solver.upper()} SOLVER - L1 PENALTY EVALUATION:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for C_value in l1_penalty_values:\n",
    "        model = l1_penalty_models[solver][C_value]\n",
    "        result = evaluate_model(model, X_test_scaled, y_test, f\"{solver}_L1_C{C_value}\")\n",
    "        l1_evaluation_results.append(result)\n",
    "        \n",
    "        print(f\"C={C_value}: Accuracy={result['Accuracy']:.4f}, F1={result['F1_Score']:.4f}\")\n",
    "\n",
    "l1_df = pd.DataFrame(l1_evaluation_results)\n",
    "print(f\"\\nL1 PENALTY MODELS SUMMARY:\")\n",
    "print(l1_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1414fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL SUMMARY - TOP PERFORMING MODELS:\n",
      "--------------------------------------------------\n",
      "Top 5 Models by Accuracy:\n",
      "                                   Model  Accuracy  Precision  Recall  \\\n",
      "0    newton-cg + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "1  newton-cg + none (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "2        lbfgs + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "3      lbfgs + none (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "4    liblinear + l1 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "\n",
      "   F1_Score  \n",
      "0    0.9756  \n",
      "1    0.9756  \n",
      "2    0.9756  \n",
      "3    0.9756  \n",
      "4    0.9756  \n",
      "\n",
      "FEATURE IMPORTANCE ANALYSIS:\n",
      "------------------------------\n",
      "Best L1 model: liblinear_L1_C0.1\n",
      "Non-zero features selected by L1 regularization:\n",
      "                 Coefficient\n",
      "radius3             1.202234\n",
      "concave_points1     0.883448\n",
      "area3               0.786302\n",
      "texture3            0.639356\n",
      "concave_points3     0.536189\n",
      "smoothness3         0.222946\n",
      "radius2             0.213371\n",
      "perimeter3          0.196545\n",
      "symmetry3           0.158822\n",
      "concavity3          0.079880\n",
      "\n",
      "Number of features selected: 10 out of 30\n",
      "Feature reduction: 66.7%\n",
      "Top 5 Models by Accuracy:\n",
      "                                   Model  Accuracy  Precision  Recall  \\\n",
      "0    newton-cg + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "1  newton-cg + none (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "2        lbfgs + l2 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "3      lbfgs + none (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "4    liblinear + l1 (before fine-tuning)    0.9825        1.0  0.9524   \n",
      "\n",
      "   F1_Score  \n",
      "0    0.9756  \n",
      "1    0.9756  \n",
      "2    0.9756  \n",
      "3    0.9756  \n",
      "4    0.9756  \n",
      "\n",
      "FEATURE IMPORTANCE ANALYSIS:\n",
      "------------------------------\n",
      "Best L1 model: liblinear_L1_C0.1\n",
      "Non-zero features selected by L1 regularization:\n",
      "                 Coefficient\n",
      "radius3             1.202234\n",
      "concave_points1     0.883448\n",
      "area3               0.786302\n",
      "texture3            0.639356\n",
      "concave_points3     0.536189\n",
      "smoothness3         0.222946\n",
      "radius2             0.213371\n",
      "perimeter3          0.196545\n",
      "symmetry3           0.158822\n",
      "concavity3          0.079880\n",
      "\n",
      "Number of features selected: 10 out of 30\n",
      "Feature reduction: 66.7%\n"
     ]
    }
   ],
   "source": [
    "# Create final summary table with all key metrics\n",
    "print(\"\\nFINAL SUMMARY - TOP PERFORMING MODELS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Combine all results\n",
    "all_results = before_fine_tuning_results + after_fine_tuning_results + l1_evaluation_results\n",
    "\n",
    "# Sort by accuracy\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "top_models = all_results_df.nlargest(5, 'Accuracy')\n",
    "\n",
    "print(\"Top 5 Models by Accuracy:\")\n",
    "print(top_models[['Model', 'Accuracy', 'Precision', 'Recall', 'F1_Score']].round(4))\n",
    "\n",
    "# Feature importance analysis from best L1 model\n",
    "print(f\"\\nFEATURE IMPORTANCE ANALYSIS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Find best L1 model\n",
    "best_l1_model_idx = l1_df['Accuracy'].idxmax()\n",
    "best_l1_model_name = l1_df.loc[best_l1_model_idx, 'Model']\n",
    "\n",
    "# Extract solver and C value from the best L1 model\n",
    "for solver in l1_compatible_solvers:\n",
    "    for C_value in l1_penalty_values:\n",
    "        if f\"{solver}_L1_C{C_value}\" == best_l1_model_name:\n",
    "            best_l1_model = l1_penalty_models[solver][C_value]\n",
    "            break\n",
    "\n",
    "print(f\"Best L1 model: {best_l1_model_name}\")\n",
    "print(f\"Non-zero features selected by L1 regularization:\")\n",
    "\n",
    "coefficients = pd.DataFrame(best_l1_model.coef_.flatten(), index=X.columns, columns=['Coefficient'])\n",
    "non_zero_features = coefficients[coefficients['Coefficient'] != 0].sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(non_zero_features)\n",
    "\n",
    "print(f\"\\nNumber of features selected: {len(non_zero_features)} out of {len(X.columns)}\")\n",
    "print(f\"Feature reduction: {(1 - len(non_zero_features)/len(X.columns))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22000f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
