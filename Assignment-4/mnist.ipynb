{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2981287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(f\"Original shapes - x_train: {x_train.shape}, x_test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63acf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF(x, c, s):\n",
    "    \"\"\"Radial Basis Function with proper broadcasting\"\"\"\n",
    "    # Calculate squared Euclidean distance\n",
    "    diff = x - c\n",
    "    squared_distance = np.sum(diff ** 2)\n",
    "    return np.exp(-squared_distance / (2 * s ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bde97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 28×28 images to 32×32 using RBF interpolation\n",
    "def convert_to_32x32_rbf(image_28x28, sigma=1.0):\n",
    "    \"\"\"Convert 28x28 image to 32x32 using RBF interpolation\"\"\"\n",
    "    # Create a 32x32 grid\n",
    "    new_image = np.zeros((32, 32))\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    old_coords = np.linspace(0, 31, 28)  # Map 28 points to 0-31 range\n",
    "    new_coords = np.arange(32)           # Full 32x32 grid\n",
    "    \n",
    "    # For each position in the new 32x32 grid\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            # Find weights based on distance to original points\n",
    "            weights = []\n",
    "            values = []\n",
    "            \n",
    "            for oi, old_i in enumerate(old_coords):\n",
    "                for oj, old_j in enumerate(old_coords):\n",
    "                    # Calculate RBF weight based on distance\n",
    "                    distance = np.sqrt((i - old_i)**2 + (j - old_j)**2)\n",
    "                    weight = np.exp(-distance**2 / (2 * sigma**2))\n",
    "                    weights.append(weight)\n",
    "                    values.append(image_28x28[oi, oj])\n",
    "            \n",
    "            # Weighted average\n",
    "            weights = np.array(weights)\n",
    "            values = np.array(values)\n",
    "            if np.sum(weights) > 0:\n",
    "                new_image[i, j] = np.sum(weights * values) / np.sum(weights)\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting training data...\")\n",
    "x_train_rbf = np.zeros((x_train.shape[0], 32, 32))\n",
    "for i in range(x_train.shape[0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Processing training sample {i}/{x_train.shape[0]}\")\n",
    "    x_train_rbf[i] = convert_to_32x32_rbf(x_train[i])\n",
    "\n",
    "print(\"Converting test data...\")\n",
    "x_test_rbf = np.zeros((x_test.shape[0], 32, 32))\n",
    "for i in range(x_test.shape[0]):\n",
    "    if i % 2000 == 0:\n",
    "        print(f\"Processing test sample {i}/{x_test.shape[0]}\")\n",
    "    x_test_rbf[i] = convert_to_32x32_rbf(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f9fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Split dataset: 80% training, 10% validation, 10% test\n",
    "train_size = int(0.8 * x_train_rbf.shape[0])\n",
    "val_size = int(0.1 * x_train_rbf.shape[0])\n",
    "\n",
    "x_train_final = x_train_rbf[:train_size]\n",
    "y_train_final = y_train[:train_size]\n",
    "\n",
    "x_val_rbf = x_train_rbf[train_size:train_size + val_size]\n",
    "y_val = y_train[train_size:train_size + val_size]\n",
    "\n",
    "# Keep only 10% of test data to match the requirement\n",
    "test_size = int(0.1 * x_test_rbf.shape[0])\n",
    "x_test_final = x_test_rbf[:test_size]\n",
    "y_test_final = y_test[:test_size]\n",
    "\n",
    "print(f\"Final dataset shapes:\")\n",
    "print(f\"Training: {x_train_final.shape}, {y_train_final.shape}\")\n",
    "print(f\"Validation: {x_val_rbf.shape}, {y_val.shape}\")\n",
    "print(f\"Test: {x_test_final.shape}, {y_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize original vs RBF converted images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(5):\n",
    "    # Original 28x28\n",
    "    axes[0, i].imshow(x_train[i], cmap='gray')\n",
    "    axes[0, i].set_title(f'Original 28x28 - Label: {y_train[i]}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # RBF converted 32x32\n",
    "    axes[1, i].imshow(x_train_rbf[i], cmap='gray')\n",
    "    axes[1, i].set_title(f'RBF 32x32 - Label: {y_train[i]}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36364f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_layers, hidden_neurons, activation, optimizer, loss):\n",
    "    \"\"\"Create a fully connected neural network model\"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(32, 32)))\n",
    "    \n",
    "    # Add hidden layers according to the number specified\n",
    "    for i in range(hidden_layers):\n",
    "        if i < len(hidden_neurons):  # Ensure we don't go out of bounds\n",
    "            model.add(tf.keras.layers.Dense(hidden_neurons[i], activation=activation))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameter combinations\n",
    "configurations = [\n",
    "    # Configuration 1: 1 hidden layer with 16 neurons\n",
    "    {'hidden_layers': 1, 'hidden_neurons': [16], 'activation': 'sigmoid'},\n",
    "    # Configuration 2: 2 hidden layers with 16, 32 neurons\n",
    "    {'hidden_layers': 2, 'hidden_neurons': [16, 32], 'activation': 'sigmoid'},\n",
    "    # Configuration 3: 3 hidden layers with 16, 32, 64 neurons\n",
    "    {'hidden_layers': 3, 'hidden_neurons': [16, 32, 64], 'activation': 'sigmoid'}\n",
    "]\n",
    "\n",
    "optimizer_loss_combinations = [\n",
    "    # Gradient Descent with Squared Error Loss\n",
    "    {'optimizer': tf.keras.optimizers.SGD(learning_rate=0.001), \n",
    "     'loss': 'mean_squared_error', \n",
    "     'optimizer_name': 'SGD'},\n",
    "    # Adam with Categorical Cross Entropy\n",
    "    {'optimizer': tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "     'loss': 'categorical_crossentropy', \n",
    "     'optimizer_name': 'Adam'}\n",
    "]\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd3679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes - x_train: (60000, 28, 28), x_test: (10000, 28, 28)\n",
      "Converting training data...\n",
      "Processing training sample 0/60000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting training for all combinations...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for config in configurations:\n",
    "    for opt_loss in optimizer_loss_combinations:\n",
    "        print(f\"\\nConfiguration: {config['hidden_layers']} layers {config['hidden_neurons']}\")\n",
    "        print(f\"Optimizer: {opt_loss['optimizer_name']}, Loss: {opt_loss['loss']}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_model(\n",
    "            config['hidden_layers'], \n",
    "            config['hidden_neurons'], \n",
    "            config['activation'],\n",
    "            opt_loss['optimizer'], \n",
    "            opt_loss['loss']\n",
    "        )\n",
    "        \n",
    "        # Convert labels based on loss function\n",
    "        if opt_loss['loss'] == 'categorical_crossentropy':\n",
    "            y_train_encoded = tf.keras.utils.to_categorical(y_train_final, 10)\n",
    "            y_val_encoded = tf.keras.utils.to_categorical(y_val, 10)\n",
    "            y_test_encoded = tf.keras.utils.to_categorical(y_test_final, 10)\n",
    "        else:  # mean_squared_error\n",
    "            y_train_encoded = tf.keras.utils.to_categorical(y_train_final, 10)\n",
    "            y_val_encoded = tf.keras.utils.to_categorical(y_val, 10)\n",
    "            y_test_encoded = tf.keras.utils.to_categorical(y_test_final, 10)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            x_train_final, y_train_encoded, \n",
    "            epochs=10, \n",
    "            validation_data=(x_val_rbf, y_val_encoded),\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        test_loss, test_acc = model.evaluate(x_test_final, y_test_encoded, verbose=0)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'hidden_layers': config['hidden_layers'],\n",
    "            'hidden_neurons': config['hidden_neurons'],\n",
    "            'activation': config['activation'],\n",
    "            'optimizer': opt_loss['optimizer_name'],\n",
    "            'loss': opt_loss['loss'],\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_loss': test_loss\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "        print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of all results\n",
    "print(\"\\nSUMMARY OF ALL RESULTS:\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Config':<15} {'Neurons':<15} {'Optimizer':<10} {'Loss':<20} {'Test Acc':<10} {'Test Loss':<10}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for result in results:\n",
    "    neurons_str = str(result['hidden_neurons'])\n",
    "    config_str = f\"{result['hidden_layers']} layers\"\n",
    "    \n",
    "    print(f\"{config_str:<15} {neurons_str:<15} {result['optimizer']:<10} {result['loss']:<20} \"\n",
    "          f\"{result['test_accuracy']:<10.4f} {result['test_loss']:<10.4f}\")\n",
    "\n",
    "# Find best performing model\n",
    "best_result = max(results, key=lambda x: x['test_accuracy'])\n",
    "print(f\"\\nBEST PERFORMING MODEL:\")\n",
    "print(f\"Configuration: {best_result['hidden_layers']} layers {best_result['hidden_neurons']}\")\n",
    "print(f\"Optimizer: {best_result['optimizer']}, Loss: {best_result['loss']}\")\n",
    "print(f\"Test Accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"Test Loss: {best_result['test_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5a93bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6350e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
